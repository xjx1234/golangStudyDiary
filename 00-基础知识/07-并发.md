## 并发

有人把Go语言比作 21 世纪的C语言，第一是因为Go语言设计简单，第二则是因为 21 世纪最重要的就是并发程序设计，而 Go 从语言层面就支持并发。同时实现了自动垃圾回收机制。

下面来介绍几个概念：

**并发/并行**

并行(parallel)：指在同一时刻，有多条指令在多个处理器上同时执行。

![](https://myvoice1.oss-cn-beijing.aliyuncs.com/github/parallel.png)



并发(concurrency)在微观上，是指在同一时刻只能有一条指令执行，但多个程序指令被快速的轮换执行，使得在宏观上具有多个进程同时执行的效果，但在微观上并不是同时执行的，只是把时间分成若干段，使多个程序快速交替的执行。并发的本质是利用cpu时间片轮转，使多个进程快速交替的执行。

![](https://myvoice1.oss-cn-beijing.aliyuncs.com/github/concurrency.png)



以咖啡机的例子来解释并行和并发的区别：

![cofe](https://myvoice1.oss-cn-beijing.aliyuncs.com/github/cofe.png)

总结的说：

- 并行是两个队列同时使用两台咖啡机 （真正的多任务）
- 并发是两个队列交替使用一台咖啡机 （ 假 的多任务）

**进程/线程/协程**

​	进程：独立地址空间，拥有PCB

​	线程：有独立的PCB，但没有独立的地址空间(共享)

​	区别：在于是否共享地址空间。独居(进程)；合租(线程)。

​	线程：最小的执行单位

​	进程：最小分配资源单位，可看成是只有一个线程的进程。

​    协程：独立的栈空间，共享堆空间，调度由用户自己控制，本质上有点类似于用户级线程，这些用户级线程的调度也是自己实现的。

### Go协程（Goroutine)

Go协程（Goroutine）是与其他[函数](http://blog.csdn.net/u011304970/article/details/74885661)或[方法](http://blog.csdn.net/u011304970/article/details/75042912)同时运行的函数或方法。可以认为Go协程是轻量级的线程。与创建线程相比，创建Go协程的成本很小。因此在Go中同时运行上千个协程是很常见的。

**协程对比线程优点**

- 与线程相比，Go协程的开销非常小。Go协程的堆栈大小只有几kb，它可以根据应用程序的需要而增长和缩小，而线程必须指定堆栈的大小，并且堆栈的大小是固定的。
- Go协程被多路复用到较少的OS线程。在一个程序中数千个Go协程可能只运行在一个线程中。如果该线程中的任何一个Go协程阻塞（比如等待用户输入），那么Go会创建一个新的OS线程并将其余的Go协程移动到这个新的OS线程。所有这些操作都是 runtime 来完成的，而我们程序员不必关心这些复杂的细节，只需要利用 Go 提供的简洁的 API 来处理并发就可以了。
- Go 协程之间通过信道（channel）进行通信。信道可以防止多个协程访问共享内存时发生竟险（race condition）。信道可以想象成多个协程之间通信的管道。我们将在下一篇教程中介绍信道

使用 go 关键字就可以创建 goroutine，将 go 声明放到一个需调用的函数之前，在相同地址空间调用运行这个函数，这样该函数执行时便会作为一个独立的并发线程，这种线程在Go语言中则被称为 goroutine。用法如下:

```go
package main

import "fmt"

func hello() {
	fmt.Println("hello goroutine")
}

func main() {
	go hello() // 开启协程调用hello函数
	//开启协程 调用匿名函数
	go func(name string) {
		fmt.Println("hello " + name + " goroutine")
	}("anonymous")
	fmt.Println("main function")
}
```

从上述例子中，我们可以总结出，创建普通协程和匿名的格式为：

> go 函数名( 参数列表 )

匿名协程：

> go func( 参数列表 ){
>   函数体
> }( 调用参数列表 )

当你运行这个程序时候，你会发现，运行结果为: `main function` ,为什么跟我们预想的不一致呢？ 这时候，我们需要了解下go协程的两个属性：

- **当创建一个Go协程时，创建这个Go协程的语句立即返回。与函数不同，程序流程不会等待Go协程结束再继续执行。程序流程在开启Go协程后立即返回并开始执行下一行代码，忽略Go协程的任何返回值。**
- **在主协程存在时才能运行其他协程，主协程终止则程序终止，其他协程也将终止。**

我想你已经知道了为什么我们的协程为什么没有运行。在11行调用 `go hello()`后，程序的流程直接调转到下一条语句执行，并没有等待 `hello` 协程退出，然后打印 `main function`。接着主协程结束运行，不会再执行任何代码，因此 `hello` 协程没有得到运行的机会。我们可以在main函数最后加上一句 `time.Sleep(1)`，程序运行结果为:

 `hello goroutine
main function
hello anonymous goroutine`

### 通道 (Channel)

Channel可以被认为是协程之间通信的管道。与水流从管道的一端流向另一端一样，数据可以从信道的一端发送并在另一端接收。Go语言提倡使用通信的方法代替共享内存，当一个资源需要在 goroutine 之间共享时，通道在 goroutine 之间架起了一个管道，并提供了确保同步交换数据的机制。声明通道时，需要指定将要被共享的数据的类型。可以通过通道共享内置类型、命名类型、结构类型和引用类型的值或者指针。这里通信的方法就是使用通道（channel），如下图所示:

![](https://myvoice1.oss-cn-beijing.aliyuncs.com/github/channel.jpg)

#### 声明通道类型

通道声明格式如下:

> var 通道变量 chan 通道类型

chan 类型的空值是 nil，声明后需要配合 make 后才能使用。

#### 创建通道

通道是引用类型，需要使用 make 进行创建，格式如下：

> 通道实例 := make(chan 数据类型)

声明与创建通道的实际用法，我们通过下面例子熟悉：

```go
	var ch1 chan int //声明通道
	ch1 = make(chan int) //创建通道
	cha2 := make(chan interface{}) //声明并创建通道
	fmt.Printf("%v, %v", ch1, cha2)
```

#### 通过通道发送接收数据

1.  通道发送数据

   通道的发送使用特殊的操作符`<-`，将数据通过通道发送的格式为：

   > 通道变量 <- 值

   

2.  通道接收数据

   通道接收同样使用`<-`操作符，通道接收有如下特性：

- 通道的收发操作在不同的两个 goroutine 间进行。

- 接收将持续阻塞直到发送方发送数据。

- 每次接收一个元素。

  

  通道的数据接收有如下写法：

> data := <-ch   //阻塞接收数据

> data, ok := <-ch //非堵塞接收数据

> <-ch // 接收任意数据，忽略接收的数据

> ​	for data := range ch { } // 循环接收

下面我们通过一个例子来说明通道的使用:

```go
func hello2(ch chan bool) {
	ch <- true
	fmt.Println("hello ch")
}
func main(){
    ch := make(chan bool)
	go hello2(ch)
	<-ch
	fmt.Println("run end")
}
```

上面程序定义了一个 bool 类型的通道 `ch` ，然后将它作为参数传输给 `hello2` 函数，然后通道 `ch` 一直在被堵塞到其他程序向通道写数据为止。本程序执行结果为：

> hello ch
> run end

我们再写一个例子，来帮助与理解通道。该程序打印一个数组的平方和立方和，平方和立方结果分别写入一个通道，最后将通道值相加，代码如下：

```go
func calSquares(num int, sumData chan int) {
	result := num * num
	sumData <- result
}

func calCubes(num int, sumData chan int) {
	result := num * num * num
	sumData <- result
}

func main(){
	squaresChan := make(chan int)
	cubesChan := make(chan int)
	go calSquares(2, squaresChan)
	go calCubes(3, cubesChan)
	s1, s2 := <-squaresChan, <-cubesChan
	fmt.Printf("the sum is %d\n", s1+s2)
}
```

这两个函数接受不同的信道作为参数，并分别运行在各自的协程中, 最后将结果写入各自的信道。主协程在同时等待这两个信道中的数据。一旦从这两个信道中接收到数据，它们分别被存放在变量 `s1` 和 `s2` 中，最后将它们的和打印出来。程序的输出为：

> the sum is 31

#### 单向通道 - 通道中的单行道

Go语言的类型系统提供了单方向的 channel 类型，顾名思义，单向 channel 只能用于发送或者接收数据。channel 本身必然是同时支持读写的，否则根本没法用。假如一个 channel 真的只能读，那么肯定只会是空的，因为你没机会往里面写数据。同理，如果一个 channel 只允许写，即使写进去了，也没有丝毫意义，因为没有机会读取里面的数据。所谓的单向 channel 概念，其实只是对 channel 的一种使用限制。

单项通道声明格式如下：

> var 通道实例 chan<- 元素类型   // 只能发送通道

> var 通道实例 <-chan 元素类型   // 只能接收通道

下面给出单项通道的使用例子：

```go
	sendOnlyChan := make(chan<- int) // 只能发送通道
	recOnlyChan := make(<-chan int) //只能接收通道
	sendOnlyChan <- 1
	<-sendOnlyChan
```

这个程序代码段，运行起来是报错的，这是非法的，程序将无法通过编译，程序会报错为：`invalid operation: <-sendOnlyChan (receive from send-only type chan<- int)`，但是如果一个通道只能读或者写，创建一个只写通道有什么用呢？**这就是信道转型的用途。可以将双向信道转换为只写或只读信道，但是反过来却不行。**，效果如下例子：

```go
package main

import "fmt"

func sendData(sendch chan<- int) {  
    sendch <- 10
}

func main() {  
    chnl := make(chan int)
    go sendData(chnl)
    fmt.Println(<-chnl)
}
```

#### 关闭通道

关闭 channel 非常简单，直接使用 Go语言内置的 close() 函数即可：

> close(ch)

在介绍了如何关闭 channel 之后，我们就多了一个问题：如何判断一个 channel 是否已经被关闭？我们可以在读取的时候使用多重返回值的方式：

> x, ok := <-ch

这个用法与 map 中的按键获取 value 的过程比较类似，只需要看第二个 bool 返回值即可，如果返回值是 false 则表示 ch 已经被关闭。

#### 无缓冲与有缓冲通道

Go语言中无缓冲的通道（unbuffered channel）是指在接收前没有能力保存任何值的通道。这种类型的通道要求发送 goroutine 和接收 goroutine 同时准备好，才能完成发送和接收操作。如果两个 goroutine 没有同时准备好，通道会导致先执行发送或接收操作的 goroutine 阻塞等待。这种对通道进行发送和接收的交互行为本身就是同步的。其中任意一个操作都无法离开另一个操作单独存在。阻塞指的是由于某种原因数据没有到达，当前协程（线程）持续处于等待状态，直到条件满足才解除阻塞。

下图展示两个 goroutine 如何利用无缓冲的通道来共享一个值：

![](https://myvoice1.oss-cn-beijing.aliyuncs.com/github/unbuffered_channel.jpg)

在第 1 步，两个 goroutine 都到达通道，但哪个都没有开始执行发送或者接收。
 在第 2 步，左侧的 goroutine 将它的手伸进了通道，这模拟了向通道发送数据的行为。这时，这个 goroutine 会在通道中被锁住，直到交换完成。
 在第 3 步，右侧的 goroutine 将它的手放入通道，这模拟了从通道里接收数据。这个 goroutine 一样也会在通道中被锁住，直到交换完成。
 在第 4 步和第 5 步，进行交换，并最终，在第 6 步，两个 goroutine 都将它们的手从通道里拿出来，这模拟了被锁住的 goroutine 得到释放。两个 goroutine 现在都可以去做别的事情了。

无缓冲channel创建格式:

> 通道实例 := make(chan 数据类型)

示例代码:

```go
func main() {
	unbufferedChan := make(chan int) //创建无缓存通道
	fmt.Printf("leb(c)=%d, cap(c)=%d\n", len(unbufferedChan), cap(unbufferedChan))
	go func() {
		defer fmt.Println("子协程结束")
		for i := 0; i < 3; i++ {
			fmt.Println("here", i)
			unbufferedChan <- i
			fmt.Printf("子进程正在运行[%d]: len(c)=%d,cap(c)=%d \n", i, len(unbufferedChan), cap(unbufferedChan))
		}
	}()
	
	for i := 0; i < 3; i++ {
		num := <-unbufferedChan
		fmt.Println("num=", num)
	}

	fmt.Println("main主程序结束")
}
```

我们先看一下运行结果再来看代码： 

```go
leb(c)=0, cap(c)=0
here 0
子进程正在运行[0]: len(c)=0,cap(c)=0
here 1
num= 0
num= 1
子进程正在运行[1]: len(c)=0,cap(c)=0
here 2
子进程正在运行[2]: len(c)=0,cap(c)=0
子协程结束
num= 2
main主程序结束

```

Go语言中有缓冲的通道（buffered channel）是一种在被接收前能存储一个或者多个值的通道。这种类型的通道并不强制要求 goroutine 之间必须同时完成发送和接收。通道会阻塞发送和接收动作的条件也会不同。只有在通道中没有要接收的值时，接收动作才会阻塞。只有在通道没有可用缓冲区容纳被发送的值时，发送动作才会阻塞。这导致有缓冲的通道和无缓冲的通道之间的一个很大的不同：无缓冲的通道保证进行发送和接收的 goroutine 会在同一时间进行数据交换；有缓冲的通道没有这种保证。示例图如下：

![](https://myvoice1.oss-cn-beijing.aliyuncs.com/github/buffered_channel.jpg)

如何创建带缓冲的通道呢？参见如下格式：

> 通道实例 := make(chan 通道类型, 缓冲大小)

下面通过一个例子中来理解带缓冲通道的用法，参见下面的代码：

```go
func main(){
    bufferedChan := make(chan int, 3)
	fmt.Printf("len(c)=%d,cap(c)=%d\n", len(bufferedChan), cap(bufferedChan))
	go func() {
		defer fmt.Println("子协程结束")
		for i := 0; i < 3; i++ {
			bufferedChan <- i
			fmt.Printf("子协程正在运行[%d]: len(c)=%d, cap(c)=%d\n", i, len(bufferedChan), cap(bufferedChan))
		}
	}()
	for i := 0; i < 3; i++ {
		num := <-bufferedChan
		fmt.Println("num=", num)
	}
	fmt.Println("main主程序结束")
}
```

我们先看一下运行结果：

```go
len(c)=0,cap(c)=3
子协程正在运行[0]: len(c)=0, cap(c)=3
子协程正在运行[1]: len(c)=1, cap(c)=3
子协程正在运行[2]: len(c)=2, cap(c)=3
子协程结束
num= 0
num= 1
num= 2
main主程序结束
```

带缓冲通道在很多特性上和无缓冲通道是类似的。无缓冲通道可以看作是长度永远为 0 的带缓冲通道。因此根据这个特性，带缓冲通道在下面列举的情况下依然会发生阻塞：

- 带缓冲通道被填满时，尝试再次发送数据时发生阻塞。
- 带缓冲通道为空时，尝试接收数据时发生阻塞。

**为什么Go语言对通道要限制长度而不提供无限长度的通道？**

我们知道通道（channel）是在两个 goroutine 间通信的桥梁。使用 goroutine 的代码必然有一方提供数据，一方消费数据。当提供数据一方的数据供给速度大于消费方的数据处理速度时，如果通道不限制长度，那么内存将不断膨胀直到应用崩溃。因此，限制通道的长度有利于约束数据提供方的供给速度，供给数据量必须在消费方处理量+通道长度的范围内，才能正常地处理数据。

#### Channel(通道)多路复用

多路复用是通信和网络中的一个专业术语。多路复用通常表示在一个信道上传输多路信号或数据流的过程和技术。

在使用通道时，想同时接收多个通道的数据是一件困难的事情。通道在接收数据时，如果没有数据可以接收将会发生阻塞。虽然可以使用如下模式进行遍历，但运行性能会非常差。

Go语言中提供了 **select** 关键字，可以同时响应多个通道的操作。select 的用法与 switch 语句非常类似，由 select 开始一个新的选择块，每个选择条件由 case 语句来描述。

与 switch 语句可以选择任何可使用相等比较的条件相比，select 有比较多的限制，其中最大的一条限制就是每个 case 语句里必须是一个 IO 操作，大致结构如下：

> select{
>   case 操作1:
>     响应操作1
>   case 操作2:
>     响应操作2
>   …
>   default:
>     没有操作情况
> }

操作1、操作2：包含通道收发语句，请参考下表：

select 多路复用中可以接收的样式

|  **操  作**  |   **语句示例**   |
| :----------: | :--------------: |
| 接收任意数据 |    case <- ch    |
|   接收变量   | case d :=  <- ch |
|   发送数据   |  case ch <- 100  |

可以看出，select 不像 switch，后面并不带判断条件，而是直接去查看 case 语句。每个 case 语句都必须是一个面向 channel 的操作。

下面我们来看个代码示例来加深对select使用和理解，代码如下:

```go
func pump1(ch chan int) {
	for i := 0; ; i++ {
		fmt.Println("pump1....")
		ch <- i * 2
	}
}

func pump2(ch chan int) {
	for i := 0; ; i++ {
		fmt.Println("pump2.....")
		ch <- i + 5
	}
}

func suck(ch1, ch2 chan int) {
	for {
		select {
		case v := <-ch1:
			fmt.Printf("Received channel1 : %d \n", v)
		case v := <-ch2:
			fmt.Printf("Received channel2 : %d \n", v)
		}
	}
}

func main(){
	ch1 := make(chan int)
	ch2 := make(chan int)
	go pump1(ch1)
	go pump2(ch2)
	go suck(ch1, ch2)
	time.Sleep(1e9)
}
```

其表达意义在于，当多个需要从多个chan中读取或写入时，会先轮询一遍所有的case，然后在所有处于就绪（可读/可写）的chan中随机挑选一个进行读取或写入操作，并执行其语句块。如果所有case都未就绪，则执行default语句，如未提供default语句，则当前协程被阻塞。

运行程序输出：

> pump1....
> pump1....
> Received channel1 : 0
> pump2.....
> Received channel1 : 2
> pump1....
> Received channel2 : 5
> Received channel1 : 4
> pump2.....
> pump2.....
> pump1....
> Received channel2 : 6
> Received channel1 : 6
> Received channel2 : 7
> pump1....
> pump1....
> pump2.....
> Received channel1 : 8
> Received channel1 : 10
> Received channel2 : 8

### 等待组

Go语言中除了可以使用通道（channel）和互斥锁进行两个并发程序间的同步外，还可以使用等待组进行多个任务的同步，等待组可以保证在并发环境中完成指定数量的任务。

在 sync.WaitGroup（等待组）类型中，每个 sync.WaitGroup 值在内部维护着一个计数，此计数的初始默认值为零。

等待组有下面几个方法可用，如下表所示:

|             方法名              |                 功能                  |
| :-----------------------------: | :-----------------------------------: |
| (wg * WaitGroup) Add(delta int) |           等待组的计数器 +1           |
|     (wg * WaitGroup) Done()     |           等待组的计数器 -1           |
|     (wg * WaitGroup) Wait()     | 当等待组计数器不等于 0 时阻塞直到变 0 |

其中Done()是Add(-1)的别名。

下面示例说明WaitGroup用法：

```go
var wg sync.WaitGroup

func pumpNum(num int) {
	defer wg.Done()
	fmt.Println(num)
}

func main(){
	for i := 0; i < 10; i++ {
		wg.Add(1)
		go pumpNum(i)
	}
	wg.Wait()
}
```

运行代码结果：

> 9
> 2
> 0
> 1
> 6
> 7
> 8
> 3
> 4
> 5

### 锁、死锁、活锁和饥饿概述

#### 互斥锁（sync.Mutex）和读写互斥锁（sync.RWMutex）

Go语言包中的 sync 包提供了两种锁类型：sync.Mutex 和 sync.RWMutex。

Mutex 是最简单的一种锁类型，同时也比较暴力，当一个 goroutine 获得了 Mutex 后，其他 goroutine 就只能乖乖等到这个 goroutine 释放该 Mutex。

RWMutex 相对友好些，是经典的单写多读模型。在读锁占用的情况下，会阻止写，但不阻止读，也就是多个 goroutine 可同时获取读锁（调用 RLock() 方法；而写锁（调用 Lock() 方法）会阻止任何其他 goroutine（无论读和写）进来，整个锁相当于由该 goroutine 独占。

sync.Mutex用法示例：

```go
package main

import (
	"fmt"
	"sync"
)

var (
	count     int
	countLock sync.Mutex
)

//获取count值
func getCount() int {
	defer countLock.Unlock()
	countLock.Lock()
	return count
}

//设置count值
func setCount(num int) {
	defer countLock.Unlock()
	countLock.Lock()
	count = num
}

func main() {
	setCount(2)
	fmt.Println(getCount())
}
```

在读多写少的环境中，可以优先使用读写互斥锁（sync.RWMutex），它比互斥锁更加高效。sync 包中的 RWMutex 提供了读写互斥锁的封装。

我们将互斥锁例子中的一部分代码修改为读写互斥锁，参见下面代码：

```go
var (
	count     int
	countLock sync.RWMutex
)
//获取count值
func getCount() int {
	defer countLock.RUnlock()
	countLock.RLock()
	return count
}
```

#### 死锁

死锁是指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。

死锁发生的条件有如下几种：

- 互拆条件

  线程对资源的访问是排他性的，如果一个线程对占用了某资源，那么其他线程必须处于等待状态，直到该资源被释放。

- 请求和保持条件

  线程 T1 至少已经保持了一个资源 R1 占用，但又提出使用另一个资源 R2 请求，而此时，资源 R2 被其他线程 T2 占用，于是该线程 T1 也必须等待，但又对自己保持的资源 R1 不释放。

- 不剥夺条件

  线程已获得的资源，在未使用完之前，不能被其他线程剥夺，只能在使用完以后由自己释放。

- 环路等待条件

  在死锁发生时，必然存在一个“进程 - 资源环形链”，即：{p0,p1,p2,...pn}，进程 p0（或线程）等待 p1 占用的资源，p1 等待 p2 占用的资源，pn 等待 p0 占用的资源。

最直观的理解是，p0 等待 p1 占用的资源，而 p1 而在等待 p0 占用的资源，于是两个进程就相互等待。如图:

![](https://myvoice1.oss-cn-beijing.aliyuncs.com/github/deadlock2.gif)

死锁解决办法：

- 如果并发查询多个表，约定访问顺序；
- 在同一个事务中，尽可能做到一次锁定获取所需要的资源；
- 对于容易产生死锁的业务场景，尝试升级锁颗粒度，使用表级锁；
- 采用分布式事务锁或者使用乐观锁

下面例子便于理解死锁的概念：

```go
type value struct {
	value int
	mu    sync.Mutex
}

var wgs sync.WaitGroup

func addValue(v1, v2 *value) {
	defer wgs.Done()
	v1.mu.Lock()
	defer v1.mu.Unlock()
	time.Sleep(2 * time.Second)
	v2.mu.Lock()
	defer v2.mu.Unlock()
	fmt.Printf("SUM:%v \n", v1.value+v2.value)
}

func main() {
	wgs.Add(2)
	var a, b value
	a.value = 5
	b.value = 4
	go addValue(&a, &b)
	go addValue(&b, &a)
	wgs.Wait()
}
```

a，b互相等待对方释放锁，形成死锁。程序输出:

> fatal error: all goroutines are asleep - deadlock!

#### 活锁

活锁是另一种形式的活跃性问题，该问题尽管不会阻塞线程，但也不能继续执行，因为线程将不断重复同样的操作，而且总会失败。

例如线程 1 可以使用资源，但它很礼貌，让其他线程先使用资源，线程 2 也可以使用资源，但它同样很绅士，也让其他线程先使用资源。就这样你让我，我让你，最后两个线程都无法使用资源。活锁通常发生在处理事务消息中，如果不能成功处理某个消息，那么消息处理机制将回滚事务，并将它重新放到队列的开头。这样，错误的事务被一直回滚重复执行，这种形式的活锁通常是由过度的错误恢复代码造成的，因为它错误地将不可修复的错误认为是可修复的错误。

当多个相互协作的线程都对彼此进行相应而修改自己的状态，并使得任何一个线程都无法继续执行时，就导致了活锁。这就像两个过于礼貌的人在路上相遇，他们彼此让路，然后在另一条路上相遇，然后他们就一直这样避让下去。如图：

![](https://myvoice1.oss-cn-beijing.aliyuncs.com/github/deadlock.gif)

下面例子便于理解活锁的概念：

```go
package main

import (
    "bytes"
    "fmt"
    "runtime"
    "sync"
    "sync/atomic"
    "time"
)

func main() {
    runtime.GOMAXPROCS(3)
    cv := sync.NewCond(&sync.Mutex{})
    go func() {
        for range time.Tick(1 * time.Second) { // 通过tick控制两个人的步调
            cv.Broadcast()
        }
    }()

    takeStep := func() {
        cv.L.Lock()
        cv.Wait()
        cv.L.Unlock()
    }

    tryDir := func(dirName string, dir *int32, out *bytes.Buffer) bool {
        fmt.Fprintf(out, " %+v", dirName)
        atomic.AddInt32(dir, 1)
        takeStep()                      //走上一步
        if atomic.LoadInt32(dir) == 1 { //走成功就返回
            fmt.Fprint(out, ". Success!")
            return true
        }
        takeStep() // 没走成功，再走回来
        atomic.AddInt32(dir, -1)
        return false
    }

    var left, right int32
    tryLeft := func(out *bytes.Buffer) bool {
        return tryDir("向左走", &left, out)
    }

    tryRight := func(out *bytes.Buffer) bool {
        return tryDir("向右走", &right, out)
    }

    walk := func(walking *sync.WaitGroup, name string) {
        var out bytes.Buffer
        defer walking.Done()
        defer func() { fmt.Println(out.String()) }()
        fmt.Fprintf(&out, "%v is trying to scoot:", name)

        for i := 0; i < 5; i++ {
            if tryLeft(&out) || tryRight(&out) {
                return
            }
        }
        fmt.Fprintf(&out, "\n%v is tried!", name)
    }

    var trail sync.WaitGroup
    trail.Add(2)
    go walk(&trail, "男人") // 男人在路上走
    go walk(&trail, "女人") // 女人在路上走
    trail.Wait()
}
```

输出结果如下：

> go run main.go
> 女人 is trying to scoot: 向左走 向右走 向左走 向右走 向左走 向右走 向左走 向右走 向左走 向右走
> 女人 is tried!
> 男人 is trying to scoot: 向左走 向右走 向左走 向右走 向左走 向右走 向左走 向右走 向左走 向右走
> 男人 is tried!

这个例子演示了使用活锁的一个十分常见的原因，两个或两个以上的并发进程试图在没有协调的情况下防止死锁。这就好比，如果走廊里的人都同意，只有一个人会移动，那就不会有活锁；一个人会站着不动，另一个人会移到另一边，他们就会继续移动。

活锁和死锁的区别在于，处于活锁的实体是在不断的改变状态，所谓的“活”，而处于死锁的实体表现为等待，活锁有可能自行解开，死锁则不能。

#### 饥饿

饥饿是指一个可运行的进程尽管能继续执行，但被调度器无限期地忽视，而不能被调度执行的情况。

与死锁不同的是，饥饿锁在一段时间内，优先级低的线程最终还是会执行的，比如高优先级的线程执行完之后释放了资源。

活锁与饥饿是无关的，因为在活锁中，所有并发进程都是相同的，并且没有完成工作。更广泛地说，饥饿通常意味着有一个或多个贪婪的并发进程，它们不公平地阻止一个或多个并发进程，以尽可能有效地完成工作，或者阻止全部并发进程。

```go
package main

import (
    "fmt"
    "runtime"
    "sync"
    "time"
)

func main() {
    runtime.GOMAXPROCS(3)

    var wg sync.WaitGroup
    const runtime = 1 * time.Second
    var sharedLock sync.Mutex

    greedyWorker := func() {
        defer wg.Done()
        var count int
        for begin := time.Now(); time.Since(begin) <= runtime; {
            sharedLock.Lock()
            time.Sleep(3 * time.Nanosecond)
            sharedLock.Unlock()
            count++
        }

        fmt.Printf("Greedy worker was able to execute %v work loops\n", count)
    }

    politeWorker := func() {
        defer wg.Done()
        var count int
        for begin := time.Now(); time.Since(begin) <= runtime; {
            sharedLock.Lock()
            time.Sleep(1 * time.Nanosecond)
            sharedLock.Unlock()

            sharedLock.Lock()
            time.Sleep(1 * time.Nanosecond)
            sharedLock.Unlock()

            sharedLock.Lock()
            time.Sleep(1 * time.Nanosecond)
            sharedLock.Unlock()
            count++
        }
        fmt.Printf("Polite worker was able to execute %v work loops\n", count)
    }

    wg.Add(2)
    go greedyWorker()
    go politeWorker()

    wg.Wait()
}
```

输出如下：

> Greedy worker was able to execute 276 work loops
> Polite worker was able to execute 92 work loops

贪婪的 worker 会贪婪地抢占共享锁，以完成整个工作循环，而平和的 worker 则试图只在需要时锁定。两种 worker 都做同样多的模拟工作（sleeping 时间为 3ns），可以看到，在同样的时间里，贪婪的 worker 工作量几乎是平和的 worker 工作量的两倍！

假设两种 worker 都有同样大小的临界区，而不是认为贪婪的 worker 的算法更有效（或调用 Lock 和 Unlock 的时候，它们也不是缓慢的），我们得出这样的结论，贪婪的 worker 不必要地扩大其持有共享锁上的临界区，井阻止（通过饥饿）平和的 worker 的 goroutine 高效工作。

不适用锁肯定会出问题。如果用了，虽然解了前面的问题，但是又出现了更多的新问题。

- 死锁：是因为错误的使用了锁，导致异常；
- 活锁：是饥饿的一种特殊情况，逻辑上感觉对，程序也一直在正常的跑，但就是效率低，逻辑上进行不下去；
- 饥饿：与锁使用的粒度有关，通过计数取样，可以判断进程的工作效率。

只要有共享资源的访问，必定要使其逻辑上进行顺序化和原子化，确保访问一致，这绕不开锁这个概念。

### Sync.Map

sync.Map这个数据结构是线程安全的（基本类型Map结构体在并发读写时会panic严重错误），它填补了Map线程不安全的缺陷，不过最好只在需要的情况下使用。它一般用于并发模型中对同一类map结构体的读写，或其他适用于sync.Map的情况。

先用传统锁的模式处理一个读写问题，示例如下:

```go
package main

import (
	"fmt"
	"sync"
)

var w sync.WaitGroup

type MyData struct {
	lock sync.RWMutex
	data map[int]int
}

func writeData(d *MyData) {
	defer d.lock.Unlock()
	defer w.Done()
	d.lock.Lock()
	for i := 0; i < 5000; i++ {
		d.data[i] = i
	}
}

func getData(i int, d *MyData) int {
	defer w.Done()
	for {
		d.lock.RLock()
		if result, ok := d.data[i]; ok {
			d.lock.RUnlock()
			fmt.Println(result)
			return result
		} else {
			d.lock.RUnlock()
			//time.Sleep(time.Microsecond * 10)
			println("waiting....")
		}
	}
}

func main() {
	var myMapData = &MyData{data: map[int]int{}}
	w.Add(2)
	go writeData(myMapData)
	go getData(4555, myMapData)
	w.Wait()
}
```

上面代码正确返回值: 4555， 我们现在尝试用 Sync.map模式同样解决这个问题看看，示例如下:

```go
package main

import (
	"fmt"
	"sync"
)
var w sync.WaitGroup
var myMapData sync.Map

func writeData(d *sync.Map) {
	defer w.Done()
	for i := 0; i < 5000; i++ {
		d.Store(i, i)
		fmt.Printf("write i:%d \n", i)
	}
}

func getData(i int, d *sync.Map) interface{} {
	defer w.Done()
	for {
		if v, ok := d.Load(i); ok {
			fmt.Printf("v is %v \n", v)
			return v
		} else {
			fmt.Printf("waiting...,statu:%v \n", ok)
		}
	}
}

func main() {
	w.Add(1)
	go writeData(&myMapData)
	go getData(1, &myMapData)
	w.Wait()
}
```



### 调整并发的运行性能

在 Go语言程序运行时（runtime）实现了一个小型的任务调度器。这套调度器的工作原理类似于操作系统调度线程，Go 程序调度器可以高效地将 CPU 资源分配给每一个任务。传统逻辑中，开发者需要维护线程池中线程与 CPU 核心数量的对应关系。同样的，Go 地中也可以通过 runtime.GOMAXPROCS() 函数做到，格式为：

> runtime.GOMAXPROCS(逻辑CPU数量)

这里的逻辑CPU数量可以有如下几种数值：

- <1：不修改任何数值。
- =1：单核心执行。
- \>1：多核并发执行。

一般情况下，可以使用 runtime.NumCPU() 查询 CPU 数量，并使用 runtime.GOMAXPROCS() 函数进行设置，例如：

> 1. runtime.GOMAXPROCS(runtime.NumCPU())

### CSP：通信顺序进程简述

后续补充

